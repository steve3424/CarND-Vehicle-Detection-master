{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for vehicle detection in video\n",
    "1. Choose features to extract from train images\n",
    "2. Transform each training image into feature vector\n",
    "3. Use these labeled feature vectors to train classifier\n",
    "4. Run classifer on entire video frames in patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw boxes function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw boxes after corners are detected\n",
    "# boxes argument is an array of tuples, one for each box to draw, 2 corners in each box\n",
    "# boxes = [((corner1), (corner2)), ((corner1), (corner2)), ((corner1), (corner2))]\n",
    "# corners = (x,y)\n",
    "def draw_boxes(img, boxes, color=(0,0,255), thick=6):\n",
    "    # make copy of image\n",
    "    draw_image = np.copy(img)\n",
    "    # draw each box in boxes list\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(draw_image, box[0], box[1], color, thick)\n",
    "    \n",
    "    return draw_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load images\n",
    "# test_images = glob.glob('test_images/*')\n",
    "# image_num = 3\n",
    "# img = mpimg.imread(test_images[image_num])\n",
    "# plt.imshow(img)\n",
    "\n",
    "# boxes = [((800,400),(950, 510)), ((1020,400),(1275,510))]\n",
    "# plt.imshow(draw_boxes(img, boxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataset(car_images, noncar_images):\n",
    "    data_dict = {}\n",
    "    data_dict['num_cars'] = len(car_images)\n",
    "    data_dict['num_noncars'] = len(noncar_images)\n",
    "    example_image = cv2.imread(car_image[0])\n",
    "    data_dict['image_shape'] = example_image.shape\n",
    "    data_dict['data_type'] = example_image.dtype\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATION\n",
    "\n",
    "+ Explore color spaces to use as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # load images\n",
    "# colorspace_cutouts = glob.glob('colorspace_cutouts/*')\n",
    "# test_images = colorspace_cutouts[6:]\n",
    "# cars = colorspace_cutouts[:3]\n",
    "# background = colorspace_cutouts[3:]\n",
    "# cutout = cv2.imread(background[0])\n",
    "# test_img = cv2.imread(test_images[2])\n",
    "\n",
    "\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# %matplotlib notebook\n",
    "\n",
    "# def plot3d(pixels, colors_rgb,\n",
    "#         axis_labels=list(\"RGB\"), axis_limits=((0, 255), (0, 255), (0, 255))):\n",
    "#     \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "#     # Create figure and 3D axes\n",
    "#     fig = plt.figure(figsize=(8, 8))\n",
    "#     ax = Axes3D(fig)\n",
    "\n",
    "#     # Set axis limits\n",
    "#     ax.set_xlim(*axis_limits[0])\n",
    "#     ax.set_ylim(*axis_limits[1])\n",
    "#     ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "#     # Set axis labels and sizes\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "#     ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "#     ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "#     ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "#     # Plot pixel values with colors given in colors_rgb\n",
    "#     ax.scatter(\n",
    "#         pixels[:, :, 0].ravel(),\n",
    "#         pixels[:, :, 1].ravel(),\n",
    "#         pixels[:, :, 2].ravel(),\n",
    "#         c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "#     return ax  # return Axes3D object for further manipulation\n",
    "\n",
    "\n",
    "# # Read a color image\n",
    "# img = cutout\n",
    "\n",
    "# # Select a small fraction of pixels to plot by subsampling it\n",
    "# scale = max(img.shape[0], img.shape[1], 64) / 64  # at most 64 rows and columns\n",
    "# img_small = cv2.resize(img, (np.int(img.shape[1] / scale), np.int(img.shape[0] / scale)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# # Convert subsampled image to desired color space(s)\n",
    "# img_small_RGB = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, matplotlib likes RGB\n",
    "# img_small_HSV = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)\n",
    "# img_small_HLS = cv2.cvtColor(img_small, cv2.COLOR_BGR2HLS)\n",
    "# img_small_LUV = cv2.cvtColor(img_small, cv2.COLOR_BGR2LUV)\n",
    "# img_small_rgb = img_small_RGB / 255.  # scaled to [0, 1], only for plotting\n",
    "\n",
    "# # show original image\n",
    "# plt.imshow(img)\n",
    "\n",
    "# # Plot and show\n",
    "# plot3d(img_small_RGB, img_small_rgb)\n",
    "# plt.show()\n",
    "\n",
    "# plot3d(img_small_HSV, img_small_rgb, axis_labels=list(\"HSV\"))\n",
    "# plt.show()\n",
    "\n",
    "# plot3d(img_small_HLS, img_small_rgb, axis_labels=list(\"HLS\"))\n",
    "# plt.show()\n",
    "\n",
    "# plot3d(img_small_LUV, img_small_rgb, axis_labels=list(\"LUV\"))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram of color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find histograms of each color channel\n",
    "def color_hist(img, nbins=32, bins_range=(0,256)):\n",
    "    # find histograms of each color channel\n",
    "    channel1 = np.histogram(img[:,:,0], nbins, bins_range)\n",
    "    channel2 = np.histogram(img[:,:,1], nbins, bins_range)\n",
    "    channel3 = np.histogram(img[:,:,2], nbins, bins_range)\n",
    "    \n",
    "    # concatenate into single feature vector\n",
    "    hist_features = np.concatenate((channel1[0], channel2[0], channel3[0]))\n",
    "    \n",
    "    ## VISUALIZATION ##\n",
    "    # calculate bin centers based on nbins and bins_range parameters\n",
    "#     bin_edges = channel1[1]\n",
    "#     bin_centers = (bin_edges[1:] + bin_edges[:len(bin_edges)-1]) / 2\n",
    "#     return channel1, channel2, channel3, bin_centers, feature_vector\n",
    "\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load images\n",
    "# template_images = glob.glob('template_images/*')\n",
    "# img = mpimg.imread(template_images[0])\n",
    "# templates = template_images[1:]\n",
    "# temp_img = mpimg.imread(templates[0])\n",
    "\n",
    "\n",
    "# channel1, channel2, channel3, bin_centers, feature_vector = color_hist(temp_img)\n",
    "\n",
    "\n",
    "# ## plot individual histograms ##\n",
    "# fig = plt.figure(figsize=(12,3))\n",
    "# plt.subplot(131)\n",
    "# plt.bar(bin_centers, rhist[0])\n",
    "# plt.xlim(0, 256)\n",
    "# plt.title('R Histogram')\n",
    "# plt.subplot(132)\n",
    "# plt.bar(bin_centers, ghist[0])\n",
    "# plt.xlim(0, 256)\n",
    "# plt.title('G Histogram')\n",
    "# plt.subplot(133)\n",
    "# plt.bar(bin_centers, bhist[0])\n",
    "# plt.xlim(0, 256)\n",
    "# plt.title('B Histogram')\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial binned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after selecting colorspace which best separates car pixels, use it to define a feature vector\n",
    "def bin_spatial(img, size=(32,32)):\n",
    "    bin_spatial_features = cv2.resize(img, size).ravel()\n",
    "    return bin_spatial_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## remove .ravel() in function\n",
    "\n",
    "# template_images = glob.glob('template_images/*')\n",
    "# img = mpimg.imread(template_images[0])\n",
    "\n",
    "# plt.imshow(img)\n",
    "# plt.imshow(bin_spatial(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HOG gradient features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gradient vector to add structural information to the classifier\n",
    "# accepts single color channel or grayscale\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    # return list of [hog_features, hog_image]\n",
    "    return_values = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell), \\\n",
    "                       cells_per_block=(cell_per_block,cell_per_block), visualize=True, feature_vector=feature_vec, \\\n",
    "                       block_norm=\"L2-Hys\")\n",
    "    \n",
    "    hog_features = return_values[0]\n",
    "    hog_image = return_values[1]\n",
    "    if vis:\n",
    "        return hog_features, hog_image\n",
    "    else:\n",
    "        return hog_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load images\n",
    "# template_images = glob.glob('template_images/*')\n",
    "# img = mpimg.imread(template_images[3])\n",
    "\n",
    "# # parameters for hog function\n",
    "# orient = 9\n",
    "# pix_cell = 8\n",
    "# cell_block = 2\n",
    "\n",
    "# # convert to gray\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# # get hog_features and hog_image\n",
    "# hog_feat, hog_img = get_hog_features(gray, orient, pix_cell, cell_block)\n",
    "\n",
    "# # show images\n",
    "# plt.figure()\n",
    "# plt.imshow(img)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(hog_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXTRACTION FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MULTIPLE IMAGES (training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to extract all feature vectors from list of images\n",
    "# inputs list of image paths\n",
    "\n",
    "def extract_features(img_list, orient, pix_per_cell, cell_per_block, color_space='RGB',\\\n",
    "                     nbins=32, spatial_size=(32,32), hog_channel='GRAY', hist_feat=True, spatial_feat=True, hog_feat=True):\n",
    "\n",
    "    # create features list, append vector for each image\n",
    "    features_list = []\n",
    "    for image in img_list:\n",
    "        # list to save selected features for each image\n",
    "        img_features = []\n",
    "        # read in image using cv2 = BGR\n",
    "        img = cv2.imread(image)\n",
    "        # convert to selected colorspace\n",
    "        if color_space == 'RGB':\n",
    "            feature_image =  cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        elif color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "        \n",
    "        # create color histogram features\n",
    "        if hist_feat:\n",
    "            hist_vector = color_hist(feature_image, nbins)\n",
    "            img_features.append(hist_vector)\n",
    "        # create spatial binned features\n",
    "        if spatial_feat:\n",
    "            spatial_vector = bin_spatial(feature_image, spatial_size)\n",
    "            img_features.append(spatial_vector)\n",
    "        # create hog features\n",
    "        if hog_feat:\n",
    "            # selected which channels of image to run hog features on (ALL, GRAY, 0, 1, or 2)\n",
    "            if hog_channel == 'GRAY':\n",
    "                gray = cv2.cvtColor(feature_image, cv2.COLOR_RGB2GRAY)\n",
    "                hog_vector = get_hog_features(gray, orient, pix_per_cell, cell_per_block)\n",
    "            elif hog_channel == 'ALL':\n",
    "                hog_vector = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.extend(get_hog_features(feature_image[:,:,channel], orient, pix_per_cell, cell_per_block))\n",
    "            else:\n",
    "                hog_vector = get_hog_features(feature_image[:,:,hog_channel], orient, pix_per_cell, cell_per_block)\n",
    "            img_features.append(hog_vector)\n",
    "            \n",
    "        # add feature vector for each image\n",
    "        features_list.append(np.concatenate(img_features))\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SINGLE IMAGES (sliding windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to extract all feature vectors from single image\n",
    "# to be called for each defined by slide_windows()\n",
    "# inputs single image plus parameters\n",
    "\n",
    "def single_image_features(image, orient, pix_per_cell, cell_per_block, color_space='RGB',\\\n",
    "                     nbins=32, spatial_size=(32,32), hog_channel='GRAY', hist_feat=True, spatial_feat=True, hog_feat=True):\n",
    "    \n",
    "    # create features list, append vector for each image\n",
    "    feature_list = []\n",
    "    # convert to selected colorspace\n",
    "    if color_space == 'RGB':\n",
    "        feature_image =  cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    elif color_space == 'HSV':\n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    elif color_space == 'LUV':\n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2LUV)\n",
    "    elif color_space == 'HLS':\n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    elif color_space == 'YUV':\n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    elif color_space == 'YCrCb':\n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # create color histogram features\n",
    "    if hist_feat:\n",
    "        hist_vector = color_hist(feature_image, nbins)\n",
    "        feature_list.append(hist_vector)\n",
    "    # create spatial binned features\n",
    "    if spatial_feat:\n",
    "        spatial_bin_vector = bin_spatial(feature_image, spatial_size)\n",
    "        feature_list.append(spatial_bin_vector)\n",
    "    # create hog features\n",
    "    if hog_feat:\n",
    "        # selected which channels of image to run hog features on (ALL, GRAY, 0, 1, or 2)\n",
    "        if hog_channel == 'GRAY':\n",
    "            gray = cv2.cvtColor(feature_image, cv2.COLOR_RGB2GRAY)\n",
    "            hog_vector = get_hog_features(gray, orient, pix_per_cell, cell_per_block)\n",
    "        elif hog_channel == 'ALL':\n",
    "            hog_vector = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], orient, pix_per_cell, cell_per_block))\n",
    "        else:\n",
    "            hog_vector = get_hog_features(feature_image[:,:,hog_channel], orient, pix_per_cell, cell_per_block)\n",
    "        feature_list.append(hog_vector)\n",
    "    \n",
    "    return np.concatenate(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPARE TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for feature extraction function\n",
    "orient = 15\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "cspace = 'HSV'\n",
    "nbins = 32\n",
    "spatial_size = (32,32)\n",
    "hog_channel = 'GRAY'\n",
    "hist_feat = True\n",
    "spatial_feat = True\n",
    "hog_feat = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training images\n",
    "cars_train = glob.glob('vehicle_training_set/vehicles_smallset/*.jpeg')\n",
    "non_cars_train = glob.glob('vehicle_training_set/non-vehicles_smallset/*.jpeg')\n",
    "\n",
    "# extract feature vectors from training images\n",
    "cars_features = extract_features(cars_train, orient, pix_per_cell, cell_per_block, color_space=cspace,\\\n",
    "                                 nbins=nbins, spatial_size=spatial_size, hog_channel='GRAY',\\\n",
    "                                hist_feat=True, spatial_feat=True, hog_feat=True)\n",
    "non_cars_features = extract_features(non_cars_train, orient, pix_per_cell, cell_per_block, color_space=cspace,\\\n",
    "                                 nbins=nbins, spatial_size=spatial_size, hog_channel='GRAY',\\\n",
    "                                hist_feat=True, spatial_feat=True, hog_feat=True)\n",
    "\n",
    "# create labels for each training set 1 == car, 0 == non-car\n",
    "cars_labels = np.ones(len(cars_features))\n",
    "non_cars_labels = np.zeros(len(non_cars_features))\n",
    "\n",
    "# combine training data and labels\n",
    "X = np.vstack((cars_features, non_cars_features)).astype(np.float64)\n",
    "y = np.hstack((cars_labels, non_cars_labels))\n",
    "\n",
    "# split train and test data\n",
    "rand_state = np.random.randint(0,100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "## scale data\n",
    "# FIT SCALER ON TRAINING SET ONLY\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# apply scaler to data\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "scaled_X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILD CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and train classifier\n",
    "clf = LinearSVC()\n",
    "clf.fit(scaled_X_train, y_train)\n",
    "\n",
    "# check accuracy on test set\n",
    "print('Accuracy of SVM on test set: ', clf.score(scaled_X_test, y_test))\n",
    "\n",
    "# ground truth test\n",
    "print('Predictions: ', clf.predict(scaled_X_test[:15]))\n",
    "print('Ground truth: ', y_test[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLIDING WINDOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a list of window boxes for searching\n",
    "# all input parameters must be 2D lists to support multiple scales\n",
    "# ONLY NEEDS OT BE RUN ON ONE IMAGE\n",
    "def slide_windows(img, x_start_stop=[[None, None]], y_start_stop=[[None, None]], \n",
    "                    xy_window=[(64, 64)], xy_overlap=[(0.5, 0.5)]):\n",
    "    \n",
    "    # checks if input parameters are of equal length\n",
    "    list_length = len(x_start_stop)\n",
    "    if (len(y_start_stop) != list_length) or (len(xy_window) != list_length) or (len(xy_overlap) != list_length):\n",
    "        raise Exception('All arguments must be of equal length!!')\n",
    "    \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # loop through each bounding area and xy_window size to create windows on multiple scales\n",
    "    for i in range(len(x_start_stop)):\n",
    "        # If x and/or y start/stop positions not defined, set to image size\n",
    "        if not x_start_stop[i][0]:\n",
    "            x_start_stop[i][0] = 0\n",
    "        if not x_start_stop[i][1]:\n",
    "            x_start_stop[i][1] = img.shape[1]\n",
    "\n",
    "        if not y_start_stop[i][0]:\n",
    "            y_start_stop[i][0] = 0\n",
    "        if not y_start_stop[i][1]:\n",
    "            y_start_stop[i][1] = img.shape[0]\n",
    "\n",
    "        # Compute the span of the region to be searched\n",
    "        xspan = x_start_stop[i][1] - x_start_stop[i][0]\n",
    "        yspan = y_start_stop[i][1] - y_start_stop[i][0]\n",
    "\n",
    "        # Compute the number of pixels per step in x/y\n",
    "        xstep = np.int(xy_window[i][0] * (1 - xy_overlap[i][0]))\n",
    "        ystep = np.int(xy_window[i][1] * (1 - xy_overlap[i][1]))\n",
    "\n",
    "        # Compute the number of windows in x/y\n",
    "        windows_x = np.int(1 + (xspan - xy_window[i][0]) / xstep)\n",
    "        windows_y = np.int(1 + (yspan - xy_window[i][1]) / ystep)\n",
    "\n",
    "        # Loop through finding x and y window positions\n",
    "        for ny in range(windows_y):\n",
    "            for nx in range(windows_x):\n",
    "                # Calculate each window position\n",
    "                x_shift = xstep * nx\n",
    "                y_shift = ystep * ny\n",
    "                top_left = (x_start_stop[i][0] + x_shift, y_start_stop[i][0] + y_shift)\n",
    "                bottom_right = (top_left[0] + xy_window[i][0], top_left[1] + xy_window[i][1])\n",
    "                # Append window position to list\n",
    "                window_list.append((top_left, bottom_right))\n",
    "    # Return the list of windows\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "template_images = glob.glob('template_images/*')\n",
    "img = cv2.imread(template_images[0])\n",
    "rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# slide_windows() parameters\n",
    "x_bounds = [[None,None], [None,None], [None,None]]\n",
    "y_bounds = [[500,575],[500,700],[100,300]] \n",
    "window = [(60,60),(200,200), (100,200)]\n",
    "overlap = [(0,0),(0,0),(0,0)]\n",
    "\n",
    "# define windows\n",
    "windows = slide_windows(img, x_start_stop=x_bounds, y_start_stop=y_bounds, xy_window=window, xy_overlap=overlap)\n",
    "boxed_image = draw_boxes(rgb, windows)\n",
    "\n",
    "# show images\n",
    "plt.figure()\n",
    "plt.imshow(rgb)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(boxed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEARCH WINDOWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts features from each window section on an image and uses the classifier to make a prediction\n",
    "def search_windows(image, windows, clf, scaler, orient, pix_per_cell, cell_per_block, color_space='RGB',\\\n",
    "                  nbins=32, size=(32,32), hog_channel='GRAY', hist_feat=True, spatial_feat=True, hog_feat=True):\n",
    "    \n",
    "    car_windows = []\n",
    "    # iterate through all windows (x,y)\n",
    "    for window in windows:\n",
    "        y_start = window[0][1]\n",
    "        y_end = window[1][1]\n",
    "        x_start = window[0][0]\n",
    "        x_end = window[1][0]\n",
    "        \n",
    "        # slice out window of original image and reshape to size of training images\n",
    "        sub_image = cv2.resize(image[y_start:y_end, x_start:x_end], (64,64))\n",
    "    \n",
    "        # extract feature vector from each sub_image\n",
    "        window_features = single_image_features(sub_image, orient, pix_per_cell, cell_per_block, color_space=color_space,\\\n",
    "                                                nbins=nbins, spatial_size=size, hog_channel=hog_channel, hist_feat=hist_feat,\\\n",
    "                                                spatial_feat=spatial_feat, hog_feat=hog_feat)\n",
    "        \n",
    "        # scale features \n",
    "        test_features = scaler.transform(np.array(window_features).reshape(1,-1))\n",
    "        \n",
    "        # make prediction for each window\n",
    "        pred = clf.predict(test_features)\n",
    "        \n",
    "        # if car was predicted, append to car_windows\n",
    "        if pred == 1:\n",
    "            car_windows.append(window)\n",
    "        \n",
    "    return car_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_boxes = search_windows(img, windows, clf, X_scaler, orient, pix_per_cell, cell_per_block, cspace, nbins, spatial_size)\n",
    "detected_image = draw_boxes(rgb, car_boxes)\n",
    "plt.imshow(detected_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
