{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for vehicle detection in video\n",
    "--CLASSIFIER TRAINING\n",
    "1. Choose features to extract from train images\n",
    "2. Transform each training image into feature vector\n",
    "3. Use these labeled feature vectors to train classifier\n",
    "\n",
    "--TRACKING PIPELINE\n",
    "1. Slice image into boxes using sliding window\n",
    "2. Run each window frame through classifier to get car prediction\n",
    "3. Save position of positive detections\n",
    "4. Use heatmap to merge duplicates and remove false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.ndimage.measurements import label\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm \n",
    "import imageio\n",
    "import time\n",
    "imageio.plugins.ffmpeg.download()\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataset(car_images, noncar_images, extract_time, vector_length, X_train, X_test):\n",
    "    data_dict = {}\n",
    "    data_dict['1.num_cars'] = len(car_images)\n",
    "    data_dict['2.num_noncars'] = len(noncar_images)\n",
    "    data_dict['3.num_features'] = vector_length\n",
    "    data_dict['4.train_size'] = len(X_train)\n",
    "    data_dict['5.test_size'] = len(X_test)\n",
    "    data_dict['6.extract_time'] = '{} seconds'.format(extract_time)\n",
    "    example_image = cv2.imread(car_images[0])\n",
    "    data_dict['7.image_shape'] = example_image.shape\n",
    "    data_dict['8.data_type'] = example_image.dtype\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw boxes after corners are detected\n",
    "# boxes = [((corner1), (corner2)), ((corner1), (corner2)), ((corner1), (corner2))]\n",
    "# corners = (x,y)\n",
    "def draw_boxes(img, boxes, color=(0,0,255), thick=6):\n",
    "    # make copy of image\n",
    "    draw_image = np.copy(img)\n",
    "    # draw each box in boxes list\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(draw_image, box[0], box[1], color, thick)\n",
    "    return draw_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes cv2 or BGR conversion\n",
    "def convert_color(img, convert='RGB'):\n",
    "    if convert == 'RGB':\n",
    "        convert_image =  cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    elif convert == 'HSV':\n",
    "        convert_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    elif convert == 'LUV':\n",
    "        convert_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "    elif convert == 'HLS':\n",
    "        convert_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    elif convert == 'YUV':\n",
    "        convert_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    elif convert == 'YCrCb':\n",
    "        convert_image = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "        \n",
    "    return convert_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find histograms of each color channel\n",
    "# returns vector length = nbins*3\n",
    "def color_hist(img, nbins=32):\n",
    "    # find histograms of each color channel\n",
    "    channel1 = np.histogram(img[:,:,0], nbins)\n",
    "    channel2 = np.histogram(img[:,:,1], nbins)\n",
    "    channel3 = np.histogram(img[:,:,2], nbins)\n",
    "    # concatenate into single feature vector\n",
    "    hist_features = np.concatenate((channel1[0], channel2[0], channel3[0]))\n",
    "    \n",
    "#     # VISUALIZATION ##\n",
    "#     # calculate bin centers based on nbins and bins_range parameters\n",
    "#     bin_edges = channel1[1]\n",
    "#     bin_centers = (bin_edges[1:] + bin_edges[:len(bin_edges)-1]) / 2\n",
    "#     return channel1, channel2, channel3, bin_centers, hist_features\n",
    "    \n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsamples image for color and spatial information\n",
    "# returns vector length = (image_area) * 3\n",
    "def bin_spatial(img, size=(32,32)):\n",
    "    # resize image and transform to vector\n",
    "    bin_spatial_features = cv2.resize(img, size).ravel()\n",
    "    return bin_spatial_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds gradient vector to add structural information to the classifier\n",
    "# accepts single color channel or grayscale\n",
    "# returns vector length = nxblocks * nyblocks * blocksize (cell**2) * orient \n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    # return list of [hog_features, hog_image]\n",
    "    return_values = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell), \\\n",
    "                       cells_per_block=(cell_per_block,cell_per_block), visualize=True, feature_vector=feature_vec, \\\n",
    "                       block_norm=\"L2-Hys\")\n",
    "    \n",
    "    hog_features = return_values[0]\n",
    "    hog_image = return_values[1]\n",
    "    \n",
    "    # returns visualization image if specified\n",
    "    if vis:\n",
    "        return hog_features, hog_image\n",
    "    else:\n",
    "        return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts all feature information from list of images\n",
    "# Use for training set\n",
    "# inputs list of image paths plus parameters\n",
    "\n",
    "def extract_features(img_list, orient, pix_per_cell, cell_per_block, color_space='RGB',\\\n",
    "                     nbins=32, spatial_size=(32,32), feature_vec=True, hog_channel='GRAY',\\\n",
    "                     hist_feat=True, spatial_feat=True, hog_feat=True):\n",
    "\n",
    "    # create features list, append vector for each image\n",
    "    features_list = []\n",
    "    for image in img_list:\n",
    "        # list to save selected features for each image\n",
    "        img_features = []\n",
    "        # read in image using cv2 = BGR\n",
    "        img = cv2.imread(image)\n",
    "        # convert to selected colorspace\n",
    "        feature_image = convert_color(img, color_space)\n",
    "        \n",
    "        # create color histogram features\n",
    "        if hist_feat:\n",
    "            hist_vector = color_hist(feature_image, nbins)\n",
    "            img_features.append(hist_vector)\n",
    "        # create spatial binned features\n",
    "        if spatial_feat:\n",
    "            spatial_vector = bin_spatial(feature_image, spatial_size)\n",
    "            img_features.append(spatial_vector)\n",
    "        # create hog features\n",
    "        if hog_feat:\n",
    "            # selected which channels of image to run hog features on (ALL, GRAY, 0, 1, or 2)\n",
    "            if hog_channel == 'GRAY':\n",
    "                gray = cv2.cvtColor(feature_image, cv2.COLOR_RGB2GRAY)\n",
    "                hog_vector = get_hog_features(gray, orient, pix_per_cell, cell_per_block, feature_vec=feature_vec)\n",
    "            elif hog_channel == 'ALL':\n",
    "                hog_vector = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_vector.extend(get_hog_features(feature_image[:,:,channel], orient, pix_per_cell, cell_per_block,\\\n",
    "                                                      feature_vec=feature_vec))\n",
    "            else:\n",
    "                hog_vector = get_hog_features(feature_image[:,:,hog_channel], orient, pix_per_cell, cell_per_block,\\\n",
    "                                             feature_vec=feature_vec)\n",
    "            img_features.append(hog_vector)\n",
    "        \n",
    "        # add feature vector for each image\n",
    "        features_list.append(np.concatenate(img_features))\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to extract all feature vectors from single image\n",
    "# Use in slide windows\n",
    "# inputs single image plus parameters\n",
    "\n",
    "def single_image_features(image, orient, pix_per_cell, cell_per_block, color_space='RGB',\\\n",
    "                     nbins=32, spatial_size=(32,32), feature_vec=True, hog_channel='GRAY',\\\n",
    "                          hist_feat=True, spatial_feat=True, hog_feat=True):\n",
    "    \n",
    "    # create features list, append vector for each image\n",
    "    feature_list = []\n",
    "    # convert to selected colorspace\n",
    "    feature_image = convert_color(image, color_space)\n",
    "    \n",
    "    # create color histogram features\n",
    "    if hist_feat:\n",
    "        hist_vector = color_hist(feature_image, nbins)\n",
    "        feature_list.append(hist_vector)\n",
    "    # create spatial binned features\n",
    "    if spatial_feat:\n",
    "        spatial_bin_vector = bin_spatial(feature_image, spatial_size)\n",
    "        feature_list.append(spatial_bin_vector)\n",
    "    # create hog features\n",
    "    if hog_feat:\n",
    "        # selected which channels of image to run hog features on (ALL, GRAY, 0, 1, or 2)\n",
    "        if hog_channel == 'GRAY':\n",
    "            gray = cv2.cvtColor(feature_image, cv2.COLOR_RGB2GRAY)\n",
    "            hog_vector = get_hog_features(gray, orient, pix_per_cell, cell_per_block, feature_vec=feature_vec)\n",
    "        elif hog_channel == 'ALL':\n",
    "            hog_vector = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_vector.extend(get_hog_features(feature_image[:,:,channel], orient, pix_per_cell, cell_per_block,\\\n",
    "                                                    feature_vec=feature_vec))\n",
    "        else:\n",
    "            hog_vector = get_hog_features(feature_image[:,:,hog_channel], orient, pix_per_cell, cell_per_block,\\\n",
    "                                         feature_vec=feature_vec)\n",
    "        feature_list.append(hog_vector)\n",
    "    \n",
    "    return np.concatenate(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all input parameters must be 2D lists to support multiple scales\n",
    "# returns a list of window boxes for searching\n",
    "\n",
    "def slide_windows(img, x_start_stop=[[None, None]], y_start_stop=[[None, None]], \n",
    "                    xy_window=[(64, 64)], xy_overlap=[(0.5, 0.5)]):\n",
    "    \n",
    "    # checks if input parameters are of equal length\n",
    "    list_length = len(x_start_stop)\n",
    "    if (len(y_start_stop) != list_length) or (len(xy_window) != list_length) or (len(xy_overlap) != list_length):\n",
    "        raise Exception('All arguments must be of equal length!!')\n",
    "    \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # loop through each bounding area and xy_window size to create windows on multiple scales\n",
    "    for i in range(len(x_start_stop)):\n",
    "        # If x and/or y start/stop positions not defined, set to image size\n",
    "        if not x_start_stop[i][0]:\n",
    "            x_start_stop[i][0] = 0\n",
    "        if not x_start_stop[i][1]:\n",
    "            x_start_stop[i][1] = img.shape[1]\n",
    "\n",
    "        if not y_start_stop[i][0]:\n",
    "            y_start_stop[i][0] = 0\n",
    "        if not y_start_stop[i][1]:\n",
    "            y_start_stop[i][1] = img.shape[0]\n",
    "\n",
    "        # Compute the span of the region to be searched\n",
    "        xspan = x_start_stop[i][1] - x_start_stop[i][0]\n",
    "        yspan = y_start_stop[i][1] - y_start_stop[i][0]\n",
    "\n",
    "        # Compute the number of pixels per step in x/y\n",
    "        xstep = np.int(xy_window[i][0] * (1 - xy_overlap[i][0]))\n",
    "        ystep = np.int(xy_window[i][1] * (1 - xy_overlap[i][1]))\n",
    "\n",
    "        # Compute the number of windows in x/y\n",
    "        windows_x = np.int(1 + (xspan - xy_window[i][0]) / xstep)\n",
    "        windows_y = np.int(1 + (yspan - xy_window[i][1]) / ystep)\n",
    "\n",
    "        # Loop through finding x and y window positions\n",
    "        for ny in range(windows_y):\n",
    "            for nx in range(windows_x):\n",
    "                # Calculate each window position\n",
    "                x_shift = xstep * nx\n",
    "                y_shift = ystep * ny\n",
    "                top_left = (x_start_stop[i][0] + x_shift, y_start_stop[i][0] + y_shift)\n",
    "                bottom_right = (top_left[0] + xy_window[i][0], top_left[1] + xy_window[i][1])\n",
    "                # Append window position to list\n",
    "                window_list.append((top_left, bottom_right))\n",
    "    # Return the list of windows\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts features from each window and classifies it\n",
    "# returns list of windows classified as car\n",
    "def search_windows(image, windows, clf, scaler, orient, pix_per_cell, cell_per_block, color_space='RGB',\\\n",
    "                  nbins=32, size=(32,32), hog_channel='GRAY', hist_feat=True, spatial_feat=True, hog_feat=True):\n",
    "    \n",
    "    car_windows = []\n",
    "    # iterate through all windows (x,y)\n",
    "    for window in windows:\n",
    "        y_start = window[0][1]\n",
    "        y_end = window[1][1]\n",
    "        x_start = window[0][0]\n",
    "        x_end = window[1][0]\n",
    "        \n",
    "        # slice out window of original image and reshape to size of training images\n",
    "        sub_image = cv2.resize(image[y_start:y_end, x_start:x_end], (64,64))\n",
    "    \n",
    "        # extract feature vector from each sub_image\n",
    "        window_features = single_image_features(sub_image, orient, pix_per_cell, cell_per_block, color_space=color_space,\\\n",
    "                                                nbins=nbins, spatial_size=size, hog_channel=hog_channel, hist_feat=hist_feat,\\\n",
    "                                                spatial_feat=spatial_feat, hog_feat=hog_feat)\n",
    "        \n",
    "        # scale features \n",
    "        test_features = scaler.transform(np.array(window_features).reshape(1,-1))\n",
    "        \n",
    "        # make prediction for each window\n",
    "        pred = clf.predict(test_features)\n",
    "        \n",
    "        # if car was predicted, append to car_windows\n",
    "        if pred == 1:\n",
    "            car_windows.append(window)\n",
    "        \n",
    "    return car_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create heatmap based on hot windows\n",
    "def add_heat(heatmap, box_list):\n",
    "    # loop through list of bounding boxes found to be cars\n",
    "    for box in box_list:\n",
    "        # add 1 for every pixel in box\n",
    "        # box = ((x1,y1),(x2,y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] +=1\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold heatmap to eliminate false positives\n",
    "def heat_thresh(heatmap, thresh):\n",
    "    heatmap[heatmap <= thresh] = 0\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw boxes around heatmap labels\n",
    "def find_heat_boxes(img, labels):\n",
    "    # array for boxes found in heat map\n",
    "    heat_boxes = []\n",
    "    # iterate through detected cars\n",
    "    for car_number in range(1, labels[1]+1): # for 2 cars iterate 1,2 instead of 0,1\n",
    "        # identify pixels \n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # find x and y values of car number pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # identify box corners\n",
    "        top_left = (np.min(nonzerox), np.min(nonzeroy))\n",
    "        bottom_right = (np.max(nonzerox), np.max(nonzeroy))\n",
    "        heat_boxes.append((top_left, bottom_right))\n",
    "    \n",
    "    return heat_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for feature extraction function\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "cspace = 'YCrCb'\n",
    "nbins = 32\n",
    "spatial_size = (32, 32)\n",
    "hog_channel = 'ALL'\n",
    "hist_feat = True\n",
    "spatial_feat = True\n",
    "hog_feat = True\n",
    "\n",
    "# slide_windows() parameters\n",
    "x_bounds = [[None,None],[None,None]]\n",
    "y_bounds = [[400,656], [400,560]] \n",
    "window = [(96,96),(64,64)] #(width,height)\n",
    "overlap = [(0.5,0.5),(0.5,0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LOAD LARGE SET TRAINING IMAGES --- png (0,255)\n",
    "cars_train = glob.glob('large_training_set/vehicles/**/*.png', recursive=True)\n",
    "non_cars_train = glob.glob('large_training_set/non-vehicles/**/*.png', recursive=True)\n",
    "\n",
    "\n",
    "# sub sample training set\n",
    "# n_samples = 1000\n",
    "# random_indices = np.random.randint(0, len(cars_train), n_samples)\n",
    "# cars_train = np.array(cars_train)[random_indices]\n",
    "# non_cars_train = np.array(non_cars_train)[random_indices]\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "# extract feature vectors from training images\n",
    "cars_features = extract_features(cars_train, orient, pix_per_cell, cell_per_block, color_space=cspace,\\\n",
    "                                 nbins=nbins, spatial_size=spatial_size, hog_channel=hog_channel,\\\n",
    "                                hist_feat=True, spatial_feat=True, hog_feat=True)\n",
    "non_cars_features = extract_features(non_cars_train, orient, pix_per_cell, cell_per_block, color_space=cspace,\\\n",
    "                                 nbins=nbins, spatial_size=spatial_size, hog_channel=hog_channel,\\\n",
    "                                hist_feat=True, spatial_feat=True, hog_feat=True)\n",
    "\n",
    "# calculate time to extract all features\n",
    "extract_time = round(time.time() - t, 2)\n",
    "\n",
    "# create labels for each training set 1 == car, 0 == non-car\n",
    "cars_labels = np.ones(len(cars_features))\n",
    "non_cars_labels = np.zeros(len(non_cars_features))\n",
    "\n",
    "# combine training data and labels\n",
    "X = np.vstack((cars_features, non_cars_features)).astype(np.float64)\n",
    "y = np.hstack((cars_labels, non_cars_labels))\n",
    "\n",
    "# split train and test data\n",
    "rand_state = np.random.randint(0,100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=rand_state)\n",
    "\n",
    "## fit scaler to training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# apply scaler to training and test data\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "scaled_X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show details of data set\n",
    "vector_length = len(X_train[0])\n",
    "data_dict = explore_dataset(cars_train, non_cars_train, extract_time, vector_length, X_train, X_test)\n",
    "for key in sorted(data_dict):\n",
    "    print('{}:\\t'.format(key), data_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUILD CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifier \n",
    "clf = svm.LinearSVC()\n",
    "\n",
    "# train classifier\n",
    "t = time.time()\n",
    "clf.fit(scaled_X_train, y_train)\n",
    "fit_time = round(time.time() - t, 2)\n",
    "accuracy = clf.score(scaled_X_test, y_test)\n",
    "\n",
    "# check accuracy on test set\n",
    "print('Accuracy of SVM on test set: {:.5f} on test set of {} images'.format(accuracy, len(X_test)))\n",
    "print(fit_time, 'seconds to train classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_vehicles(image):\n",
    "    t = time.time()\n",
    "    \n",
    "    # define search windows in image\n",
    "    image_windows = slide_windows(image, x_start_stop=x_bounds, y_start_stop=y_bounds, xy_window=window, xy_overlap=overlap)\n",
    "    # output list of search windows with positive detection\n",
    "    car_windows = search_windows(image, image_windows, clf, X_scaler, orient, pix_per_cell, cell_per_block,\\\n",
    "                                 color_space=cspace, nbins=nbins, size=spatial_size, hog_channel=hog_channel,\\\n",
    "                                hist_feat=hist_feat, spatial_feat=spatial_feat, hog_feat=hog_feat)\n",
    "    \n",
    "#     # create empty heatmap\n",
    "#     heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "#     # add heat from car_windows\n",
    "#     heatmap = add_heat(heatmap, car_windows)\n",
    "#     # threshold heatmap\n",
    "#     heatmap = heat_thresh(heatmap, 1)\n",
    "#     # create labels from heat map\n",
    "#     heat_labels = label(heatmap)\n",
    "#     # find boxes from heatmap\n",
    "#     hot_boxes = find_heat_boxes(image, heat_labels)\n",
    "    \n",
    "    # draw boxes onto image\n",
    "    draw_img = np.copy(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "#     draw_img = draw_boxes(draw_img, hot_boxes)\n",
    "    window_img = draw_boxes(draw_img, car_windows)\n",
    "    \n",
    "    print('run time: ', round(time.time()-t), ' seconds')\n",
    "    print('searching {} windows'.format(len(image_windows)))\n",
    "    print('')\n",
    "    return window_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test_images --- jpeg and png (0,255)\n",
    "# PNG == cv2.imread() RGB\n",
    "# JPG == cv2.imread() BGR\n",
    "test_images = glob.glob('test_images/*')\n",
    "\n",
    "\n",
    "image_list = []\n",
    "for i,image in enumerate(test_images):\n",
    "    # convert image\n",
    "    image_bgr = cv2.imread(image)\n",
    "    # for last 2 png images\n",
    "    if i > 6:\n",
    "        img = cv2.imread(image)\n",
    "        image_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # run test image through pipeline\n",
    "    detected_image = detect_vehicles(image_bgr)\n",
    "    # append processed image to list\n",
    "    image_list.append(detected_image)\n",
    "    \n",
    "    \n",
    "# show images\n",
    "for img in image_list:\n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create video\n",
    "vid_output = 'output_images/output_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(detect_vehicles) \n",
    "%time white_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # output video\n",
    "# HTML(\"\"\"\n",
    "# <video width=\"960\" height=\"540\" controls>\n",
    "#   <source src=\"{0}\">\n",
    "# </video>\n",
    "# \"\"\".format(vid_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "### HISTOGRAM VISUALIZATION ###\n",
    "#####################\n",
    "\n",
    "# # load images\n",
    "# cutout_images = glob.glob('cutout_images/cars/*')\n",
    "# img = cv2.imread(cutout_images[0])\n",
    "# img = cv2.resize(img, (2560,2560))\n",
    "# img = convert_color(img, convert='HSV')\n",
    "\n",
    "# features = color_hist(img)\n",
    "# plt.imshow(img)\n",
    "\n",
    "# print(len(features))\n",
    "\n",
    "# # channel1, channel2, channel3, bin_centers, feature_vector = color_hist(temp_img)\n",
    "\n",
    "# # ## plot individual histograms ##\n",
    "# # fig = plt.figure(figsize=(12,3))\n",
    "# # plt.subplot(131)\n",
    "# # plt.bar(bin_centers, channel1[0])\n",
    "# # plt.xlim(0, 256)\n",
    "# # plt.title('Channel 1 Histogram')\n",
    "# # plt.subplot(132)\n",
    "# # plt.bar(bin_centers, channel2[0])\n",
    "# # plt.xlim(0, 256)\n",
    "# # plt.title('Channel 2 Histogram')\n",
    "# # plt.subplot(133)\n",
    "# # plt.bar(bin_centers, channel3[0])\n",
    "# # plt.xlim(0, 256)\n",
    "# # plt.title('Channel 3 Histogram')\n",
    "# # fig.tight_layout()\n",
    "\n",
    "\n",
    "#####################\n",
    "### SPATIAL BIN VISUALIZATION ###\n",
    "#####################\n",
    "\n",
    "# ## remove .ravel() in function\n",
    "\n",
    "# cutout_images = glob.glob('cutout_images/cars/*')\n",
    "# img = cv2.imread(cutout_images[0])\n",
    "\n",
    "# features = bin_spatial(img, size=(64,64))\n",
    "# print(len(features))\n",
    "\n",
    "# # show image\n",
    "# # plt.imshow(img)\n",
    "# # plt.imshow(bin_spatial(img, size=(64,64)))\n",
    "\n",
    "\n",
    "#####################\n",
    "### HOG VISUALIZATION ###\n",
    "#####################\n",
    "    \n",
    "# # load images\n",
    "# template_images = glob.glob('cutout_images/cars/*')\n",
    "# img = cv2.imread(template_images[3])\n",
    "\n",
    "# # parameters for hog function\n",
    "# orient = 10\n",
    "# pix_cell = 6\n",
    "# cell_block = 4\n",
    "\n",
    "# # convert to gray\n",
    "# gray = cv2.cvtColor(img_r, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# # get hog_features and hog_image\n",
    "# hog_feat, hog_img = get_hog_features(gray, orient, pix_cell, cell_block, vis=True)\n",
    "\n",
    "# # show images\n",
    "# plt.figure()\n",
    "# plt.imshow(img)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(hog_img, cmap='gray')\n",
    "\n",
    "\n",
    "#####################\n",
    "### SLIDING WINDOW VISUALIZATION ###\n",
    "#####################\n",
    "\n",
    "# # load images\n",
    "# test_images = glob.glob('test_images/*')\n",
    "# img = cv2.imread(test_images[6])\n",
    "# rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # define windows\n",
    "# windows = slide_windows(img, x_start_stop=x_bounds, y_start_stop=y_bounds, xy_window=window, xy_overlap=overlap)\n",
    "# boxed_image = draw_boxes(rgb, windows)\n",
    "\n",
    "# # show images\n",
    "# plt.figure()\n",
    "# plt.imshow(rgb)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(boxed_image)\n",
    "\n",
    "#####################\n",
    "### HOT WINDOWS VISUALIZATION ###\n",
    "#####################\n",
    "\n",
    "\n",
    "# car_boxes = search_windows(img, windows, clf, X_scaler, orient, pix_per_cell, cell_per_block, color_space=cspace,\\\n",
    "#                            nbins=nbins, size=spatial_size, hog_channel=hog_channel,\\\n",
    "#                            hist_feat=hist_feat, spatial_feat=spatial_feat, hog_feat=hog_feat)\n",
    "# detected_image = draw_boxes(rgb, car_boxes)\n",
    "# plt.imshow(detected_image)\n",
    "\n",
    "#####################\n",
    "### HEAT MAP VISUALIZATION ###\n",
    "#####################\n",
    "\n",
    "\n",
    "# box_list = car_boxes # use car boxes from previous cell\n",
    "# image = detected_image # use detected image from previous cell\n",
    "# heatmap = np.zeros_like(image[:,:,0]).astype(np.float) # define heatmap\n",
    "\n",
    "# # create heatmap\n",
    "# heat = add_heat(heatmap, box_list)\n",
    "# heat = heat_thresh(heat, 1)\n",
    "# # create labels from heatmap\n",
    "# labels = label(heatmap)\n",
    "# print(labels[1], 'cars found')\n",
    "\n",
    "# # find and draw box boundaries based on heat map\n",
    "# heat_boxes = find_heat_boxes(image, labels)\n",
    "# heatbox_image = draw_boxes(img, heat_boxes)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(image)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(heat, cmap='hot')\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(heatbox_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
