{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vehicle Detection Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. \n",
    "* Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from collections import deque\n",
    "from scipy.ndimage.measurements import label\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import svm \n",
    "\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataset(car_images, noncar_images, extract_time, vector_length, X_train, X_test):\n",
    "    data_dict = {}\n",
    "    data_dict['1.num_cars'] = len(car_images)\n",
    "    data_dict['2.num_noncars'] = len(noncar_images)\n",
    "    data_dict['3.num_features'] = vector_length\n",
    "    data_dict['4.train_size'] = len(X_train)\n",
    "    data_dict['5.test_size'] = len(X_test)\n",
    "    if extract_time > 60:\n",
    "        data_dict['6.extract_time'] = '{} minutes and {} seconds'.format(extract_time//60, extract_time%60)\n",
    "    else:\n",
    "        data_dict['6.extract_time'] = '{} seconds'.format(extract_time)\n",
    "    data_dict['7.extract_per_img'] = '{} seconds'.format(extract_time / (len(car_images) + len(noncar_images)))\n",
    "    example_image = cv2.imread(car_images[0])\n",
    "    data_dict['8.image_shape'] = example_image.shape\n",
    "    data_dict['9.data_type'] = example_image.dtype\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw boxes after corners are detected\n",
    "# boxes = [((corner1), (corner2)), ((corner1), (corner2)), ((corner1), (corner2))]\n",
    "# corners = (x,y)\n",
    "def draw_boxes(img, boxes, color=(0,0,255), thick=6):\n",
    "    # make copy of image\n",
    "    draw_image = np.copy(img)\n",
    "    # draw each box in boxes list\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(draw_image, box[0], box[1], color, thick)\n",
    "    return draw_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes cv2 or BGR conversion\n",
    "def convert_color(img, convert='RGB'):\n",
    "    if convert == 'RGB':\n",
    "        convert_image =  cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    elif convert == 'HSV':\n",
    "        convert_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    elif convert == 'LUV':\n",
    "        convert_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "    elif convert == 'HLS':\n",
    "        convert_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    elif convert == 'YUV':\n",
    "        convert_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    elif convert == 'YCrCb':\n",
    "        convert_image = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "        \n",
    "    return convert_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find histograms of each color channel\n",
    "# returns vector length = nbins*3\n",
    "def color_hist(img, nbins=32):\n",
    "    # find histograms of each color channel\n",
    "    channel1 = np.histogram(img[:,:,0], nbins)\n",
    "    channel2 = np.histogram(img[:,:,1], nbins)\n",
    "    channel3 = np.histogram(img[:,:,2], nbins)\n",
    "    # concatenate into single feature vector\n",
    "    hist_features = np.concatenate((channel1[0], channel2[0], channel3[0]))\n",
    "    \n",
    "#     # VISUALIZATION ##\n",
    "#     # calculate bin centers based on nbins and bins_range parameters\n",
    "#     bin_edges = channel1[1]\n",
    "#     bin_centers = (bin_edges[1:] + bin_edges[:len(bin_edges)-1]) / 2\n",
    "#     return channel1, channel2, channel3, bin_centers, hist_features\n",
    "    \n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsamples image for color and spatial information\n",
    "# returns vector length = (image_area) * 3\n",
    "def bin_spatial(img, size=(32,32)):\n",
    "    # resize image and transform to vector\n",
    "    bin_spatial_features = cv2.resize(img, size).ravel()\n",
    "    return bin_spatial_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds gradient vector to add structural information to the classifier\n",
    "# accepts single color channel or grayscale\n",
    "# returns vector length = nxblocks * nyblocks * blocksize (cell**2) * orient \n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    # return list of [hog_features, hog_image]\n",
    "    return_values = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\\\n",
    "                        cells_per_block=(cell_per_block,cell_per_block), visualize=True, feature_vector=feature_vec,\\\n",
    "                        block_norm=\"L2-Hys\")\n",
    "    \n",
    "    hog_features = return_values[0]\n",
    "    hog_image = return_values[1]\n",
    "    \n",
    "    # returns visualization image if specified\n",
    "    if vis:\n",
    "        return hog_features, hog_image\n",
    "    else:\n",
    "        return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts all feature information from list of images\n",
    "# Use for training set\n",
    "# inputs list of image paths plus parameters\n",
    "\n",
    "def extract_features(img_list, orient, pix_per_cell, cell_per_block, color_space='RGB',\\\n",
    "                     nbins=32, spatial_size=(32,32), feature_vec=True, hog_channel='ALL',\\\n",
    "                     hog_feat=True, hist_feat=True, spatial_feat=True):\n",
    "\n",
    "    # create features list, append vector for each image\n",
    "    features_list = []\n",
    "    for image in img_list:\n",
    "        # list to save selected features for each image\n",
    "        img_features = []\n",
    "        # read in image using cv2 = BGR\n",
    "        img = cv2.imread(image)\n",
    "        # convert to selected colorspace\n",
    "        feature_image = convert_color(img, color_space)\n",
    "        \n",
    "        # create hog features\n",
    "        if hog_feat:\n",
    "            # selected which channels of image to run hog features on (ALL, GRAY, 0, 1, or 2)\n",
    "            if hog_channel == 'GRAY':\n",
    "                gray = cv2.cvtColor(feature_image, cv2.COLOR_RGB2GRAY)\n",
    "                hog_vector = get_hog_features(gray, orient, pix_per_cell, cell_per_block, feature_vec=feature_vec)\n",
    "            elif hog_channel == 'ALL':\n",
    "                hog_vector = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_vector.extend(get_hog_features(feature_image[:,:,channel], orient, pix_per_cell, cell_per_block,\\\n",
    "                                                      feature_vec=feature_vec))\n",
    "            else:\n",
    "                hog_vector = get_hog_features(feature_image[:,:,hog_channel], orient, pix_per_cell, cell_per_block,\\\n",
    "                                             feature_vec=feature_vec)\n",
    "            img_features.append(hog_vector)\n",
    "        # create color histogram features\n",
    "        if hist_feat:\n",
    "            hist_vector = color_hist(feature_image, nbins)\n",
    "            img_features.append(hist_vector)\n",
    "        # create spatial binned features\n",
    "        if spatial_feat:\n",
    "            spatial_vector = bin_spatial(feature_image, spatial_size)\n",
    "            img_features.append(spatial_vector)\n",
    "        \n",
    "        # add feature vector for each image\n",
    "        features_list.append(np.concatenate(img_features))\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to extract all feature vectors from single image\n",
    "# Use in slide windows\n",
    "# inputs single image plus parameters\n",
    "\n",
    "def single_image_features(image, orient, pix_per_cell, cell_per_block, color_space='RGB',\\\n",
    "                          nbins=32, spatial_size=(32,32), feature_vec=True, hog_channel='ALL',\\\n",
    "                          hog_feat=True, hist_feat=True, spatial_feat=True):\n",
    "    \n",
    "    # create features list, append vector for each image\n",
    "    feature_list = []\n",
    "    # convert to selected colorspace\n",
    "    feature_image = convert_color(image, color_space)\n",
    "    \n",
    "    # create hog features\n",
    "    if hog_feat:\n",
    "        # selected which channels of image to run hog features on (ALL, GRAY, 0, 1, or 2)\n",
    "        if hog_channel == 'GRAY':\n",
    "            gray = cv2.cvtColor(feature_image, cv2.COLOR_RGB2GRAY)\n",
    "            hog_vector = get_hog_features(gray, orient, pix_per_cell, cell_per_block, feature_vec=feature_vec)\n",
    "        elif hog_channel == 'ALL':\n",
    "            hog_vector = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_vector.extend(get_hog_features(feature_image[:,:,channel], orient, pix_per_cell, cell_per_block,\\\n",
    "                                                    feature_vec=feature_vec))\n",
    "        else:\n",
    "            hog_vector = get_hog_features(feature_image[:,:,hog_channel], orient, pix_per_cell, cell_per_block,\\\n",
    "                                         feature_vec=feature_vec)\n",
    "        feature_list.append(hog_vector)\n",
    "    # create color histogram features\n",
    "    if hist_feat:\n",
    "        hist_vector = color_hist(feature_image, nbins)\n",
    "        feature_list.append(hist_vector)\n",
    "    # create spatial binned features\n",
    "    if spatial_feat:\n",
    "        spatial_bin_vector = bin_spatial(feature_image, spatial_size)\n",
    "        feature_list.append(spatial_bin_vector)\n",
    "    \n",
    "    return np.concatenate(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all input parameters must be 2D lists to support multiple scales\n",
    "# returns a list of window boxes for searching\n",
    "\n",
    "def slide_windows(img, x_start_stop=[[None, None]], y_start_stop=[[None, None]], \n",
    "                    xy_window=[(64, 64)], xy_overlap=[(0.5, 0.5)]):\n",
    "    \n",
    "    # checks if input parameters are of equal length\n",
    "    list_length = len(x_start_stop)\n",
    "    if (len(y_start_stop) != list_length) or (len(xy_window) != list_length) or (len(xy_overlap) != list_length):\n",
    "        raise Exception('All arguments must be of equal length!!')\n",
    "    \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # loop through each bounding area and xy_window size to create windows on multiple scales\n",
    "    for i in range(len(x_start_stop)):\n",
    "        # If x and/or y start/stop positions not defined, set to image size\n",
    "        if not x_start_stop[i][0]:\n",
    "            x_start_stop[i][0] = 0\n",
    "        if not x_start_stop[i][1]:\n",
    "            x_start_stop[i][1] = img.shape[1]\n",
    "\n",
    "        if not y_start_stop[i][0]:\n",
    "            y_start_stop[i][0] = 0\n",
    "        if not y_start_stop[i][1]:\n",
    "            y_start_stop[i][1] = img.shape[0]\n",
    "\n",
    "        # Compute the span of the region to be searched\n",
    "        xspan = x_start_stop[i][1] - x_start_stop[i][0]\n",
    "        yspan = y_start_stop[i][1] - y_start_stop[i][0]\n",
    "\n",
    "        # Compute the number of pixels per step in x/y\n",
    "        xstep = np.int(xy_window[i][0] * (1 - xy_overlap[i][0]))\n",
    "        ystep = np.int(xy_window[i][1] * (1 - xy_overlap[i][1]))\n",
    "\n",
    "        # Compute the number of windows in x/y\n",
    "        windows_x = np.int(1 + (xspan - xy_window[i][0]) / xstep)\n",
    "        windows_y = np.int(1 + (yspan - xy_window[i][1]) / ystep)\n",
    "\n",
    "        # Loop through finding x and y window positions\n",
    "        for ny in range(windows_y):\n",
    "            for nx in range(windows_x):\n",
    "                # Calculate each window position\n",
    "                x_shift = xstep * nx\n",
    "                y_shift = ystep * ny\n",
    "                top_left = (x_start_stop[i][0] + x_shift, y_start_stop[i][0] + y_shift)\n",
    "                bottom_right = (top_left[0] + xy_window[i][0], top_left[1] + xy_window[i][1])\n",
    "                # Append window position to list\n",
    "                window_list.append((top_left, bottom_right))\n",
    "    # Return the list of windows\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts features from each window and classifies it\n",
    "# returns list of windows classified as car\n",
    "def search_windows(image, windows, clf, scaler, orient, pix_per_cell, cell_per_block, color_space='RGB',\\\n",
    "                   nbins=32, size=(32,32), hog_channel='ALL', hog_feat=True, hist_feat=True, spatial_feat=True):\n",
    "    \n",
    "    car_windows = []\n",
    "    # iterate through all windows (x,y)\n",
    "    for window in windows:\n",
    "        y_start = window[0][1]\n",
    "        y_end = window[1][1]\n",
    "        x_start = window[0][0]\n",
    "        x_end = window[1][0]\n",
    "        \n",
    "        # slice out window of original image and reshape to size of training images\n",
    "        sub_image = cv2.resize(image[y_start:y_end, x_start:x_end], (64,64))\n",
    "    \n",
    "        # extract feature vector from each sub_image\n",
    "        window_features = single_image_features(sub_image, orient, pix_per_cell, cell_per_block, color_space=color_space,\\\n",
    "                                                nbins=nbins, spatial_size=size, hog_channel=hog_channel, hog_feat=hog_feat,\\\n",
    "                                                hist_feat=hist_feat, spatial_feat=spatial_feat)\n",
    "        \n",
    "        # scale features \n",
    "        test_features = scaler.transform(np.array(window_features).reshape(1,-1))\n",
    "        \n",
    "        # make prediction for each window\n",
    "        pred = clf.predict(test_features)\n",
    "        \n",
    "        # if car was predicted, append to car_windows\n",
    "        if pred == 1:\n",
    "            car_windows.append(window)\n",
    "        \n",
    "    return car_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hog subsampling to speed up search\n",
    "# calculates all feature vectors, runs through classifier, outputs list of positive window detections\n",
    "def subsample(image, ybounds_list, xbounds_list, scale_list, clf, scaler, orient, pix_per_cell, cell_per_block, color_space='RGB',\\\n",
    "              nbins=32, size=(32,32), hog_channel='ALL', hog_feat=True, hist_feat=True, spatial_feat=True):\n",
    "    \n",
    "    # define array to save positive window detections for draw_boxes()\n",
    "    car_windows = []\n",
    "    \n",
    "    # total window count\n",
    "    count = 0\n",
    "    \n",
    "    # loop through list of ybounds and scales\n",
    "    for i in range(len(ybounds_list)):\n",
    "        ybounds = ybounds_list[i]\n",
    "        xbounds = xbounds_list[i]\n",
    "        scale = scale_list[i]\n",
    "        \n",
    "        # crop image\n",
    "        search_img = image[ybounds[0]:ybounds[1], xbounds[0]:xbounds[1]]\n",
    "        # convert colorspace\n",
    "        convert_img = convert_color(search_img, color_space)\n",
    "        # scale img\n",
    "        if scale != 1:\n",
    "            shape = convert_img.shape\n",
    "            convert_img = cv2.resize(convert_img, (np.int(shape[1]/scale), np.int(shape[0]/scale)))\n",
    "\n",
    "        channel1 = convert_img[:,:,0]\n",
    "        channel2 = convert_img[:,:,1]\n",
    "        channel3 = convert_img[:,:,2]\n",
    "\n",
    "        # define blocks and steps\n",
    "        nxblocks = (channel1.shape[1] // pix_per_cell) - 1\n",
    "        nyblocks = (channel1.shape[0] // pix_per_cell) - 1\n",
    "        nfeat_per_block = orient*cell_per_block**2\n",
    "        window = 64\n",
    "        nblocks_per_window = (window // pix_per_cell) - 1\n",
    "        cell_per_step = 2\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cell_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cell_per_step\n",
    "\n",
    "        # compute HOG features for channels specified by hog_channel argument\n",
    "        if hog_feat:\n",
    "            if hog_channel == 'ALL':\n",
    "                hog1 = get_hog_features(channel1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "                hog2 = get_hog_features(channel2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "                hog3 = get_hog_features(channel3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "            elif hog_channel == 0:\n",
    "                hog1 = get_hog_features(channel1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "            elif hog_channel == 1:\n",
    "                hog2 = get_hog_features(channel2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "            elif hog_channel == 2:\n",
    "                hog3 = get_hog_features(channel3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "            elif hog_channel == 'GRAY':\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                hog_gray = get_hog_features(gray, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "\n",
    "        # loop through steps\n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                # count # of windows\n",
    "                count += 1\n",
    "                # array for list of selected feature vectors\n",
    "                feature_list = []\n",
    "\n",
    "                # top left of each HOG block\n",
    "                xpos = xb*cell_per_step\n",
    "                ypos = yb*cell_per_step\n",
    "\n",
    "                # slice pre-computed HOG array for this window\n",
    "                if hog_feat:\n",
    "                    if hog_channel == 'ALL':\n",
    "                        hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                        hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                        hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                        hog_vector = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "                    elif hog_channel == 0:\n",
    "                        hog_vector = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                    elif hog_channel == 1:\n",
    "                        hog_vector = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                    elif hog_channel == 2:\n",
    "                        hog_vector = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                    elif hog_channel == 'GRAY':\n",
    "                        hog_vector = hog_gray[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "                    # append selected hog features to feature list\n",
    "                    feature_list.append(hog_vector)\n",
    "\n",
    "                # extract image patch and resize to test image size (64,64)\n",
    "                xleft = xpos*pix_per_cell\n",
    "                ytop = ypos*pix_per_cell\n",
    "                sub_image = cv2.resize(convert_img[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "\n",
    "                # get color features\n",
    "                if hist_feat:\n",
    "                    hist_vector = color_hist(sub_image, nbins)\n",
    "                    feature_list.append(hist_vector)\n",
    "                if spatial_feat:\n",
    "                    spatial_vector = bin_spatial(sub_image, size)\n",
    "                    feature_list.append(spatial_vector)\n",
    "                # stack all feature vectors\n",
    "                test_features = np.concatenate(feature_list).reshape(1,-1)\n",
    "                # scale vector\n",
    "                scaled_test_features = scaler.transform(test_features)\n",
    "\n",
    "                # make prediction\n",
    "                pred = clf.predict(scaled_test_features)\n",
    "\n",
    "                # if car is detected, save box\n",
    "                if pred == 1:\n",
    "                    xleft_box = np.int(xleft*scale)\n",
    "                    ytop_box = np.int(ytop*scale)\n",
    "                    win_box = np.int(window*scale)\n",
    "                    top_left = (xleft_box+xbounds[0], ytop_box+ybounds[0])\n",
    "                    bottom_right = (xleft_box+win_box+xbounds[0], ytop_box+win_box+ybounds[0])\n",
    "                    car_windows.append((top_left, bottom_right))\n",
    "                \n",
    "            \n",
    "    return car_windows, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create heatmap based on hot windows\n",
    "def add_heat(heatmap, box_list):\n",
    "    # loop through list of bounding boxes found to be cars\n",
    "    for box in box_list:\n",
    "        # add 1 for every pixel in box\n",
    "        # box = ((x1,y1),(x2,y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] +=1\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold heatmap to eliminate false positives\n",
    "def heat_thresh(heatmap, thresh):\n",
    "    heatmap[heatmap <= thresh] = 0\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw boxes around heatmap labels\n",
    "def find_heat_boxes(img, labels):\n",
    "    # array for boxes found in heat map\n",
    "    heat_boxes = []\n",
    "    # iterate through detected cars\n",
    "    for car_number in range(1, labels[1]+1): # for 2 cars iterate 1,2 instead of 0,1\n",
    "        # identify pixels \n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # find x and y values of car number pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # identify box corners\n",
    "        top_left = (np.min(nonzerox), np.min(nonzeroy))\n",
    "        bottom_right = (np.max(nonzerox), np.max(nonzeroy))\n",
    "        heat_boxes.append((top_left, bottom_right))\n",
    "    \n",
    "    return heat_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for feature extraction function\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "cspace = 'YCrCb'\n",
    "nbins = 32\n",
    "spatial_size = (32, 32)\n",
    "hog_channel = 'ALL'\n",
    "hog_feat = True\n",
    "hist_feat = True\n",
    "spatial_feat = True\n",
    "\n",
    "# slide_windows() parameters\n",
    "x_bounds = [[None,None],[None,None]]\n",
    "y_bounds = [[400,656], [400,560]] \n",
    "window = [(96,96),(64,64)] #(width,height)\n",
    "overlap = [(0.5,0.5),(0.5,0.5)]\n",
    "\n",
    "# subsample() parameters\n",
    "ybounds_list = [[400,496],[400,528],[464,660]]\n",
    "xbounds_list = [[300,1280],[300,1280],[300,1280]]\n",
    "scale_list = [1, 1.5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LOAD LARGE SET TRAINING IMAGES --- png BGR (0,255)\n",
    "cars_train = glob.glob('large_training_set/vehicles/**/*.png', recursive=True)\n",
    "non_cars_train = glob.glob('large_training_set/non-vehicles/**/*.png', recursive=True)\n",
    "\n",
    "# sub sample training set\n",
    "# n_samples = 1000\n",
    "# random_indices = np.random.randint(0, len(cars_train), n_samples)\n",
    "# cars_train = np.array(cars_train)[random_indices]\n",
    "# non_cars_train = np.array(non_cars_train)[random_indices]\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "# # extract feature vectors from training images\n",
    "cars_features = extract_features(cars_train, orient, pix_per_cell, cell_per_block, color_space=cspace,\\\n",
    "                                 nbins=nbins, spatial_size=spatial_size, hog_channel=hog_channel,\\\n",
    "                                 hog_feat=hog_feat, hist_feat=hist_feat, spatial_feat=spatial_feat)\n",
    "non_cars_features = extract_features(non_cars_train, orient, pix_per_cell, cell_per_block, color_space=cspace,\\\n",
    "                                     nbins=nbins, spatial_size=spatial_size, hog_channel=hog_channel,\\\n",
    "                                     hog_feat=hog_feat, hist_feat=hist_feat, spatial_feat=spatial_feat)\n",
    "\n",
    "# # calculate time to extract all features\n",
    "extract_time = time.time() - t\n",
    "\n",
    "# create labels for each training set 1 == car, 0 == non-car\n",
    "cars_labels = np.ones(len(cars_features))\n",
    "non_cars_labels = np.zeros(len(non_cars_features))\n",
    "\n",
    "# combine training data and labels\n",
    "X = np.vstack((cars_features, non_cars_features)).astype(np.float64)\n",
    "y = np.hstack((cars_labels, non_cars_labels))\n",
    "\n",
    "# split train and test data\n",
    "rand_state = np.random.randint(0,100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=rand_state)\n",
    "\n",
    "## fit scaler to training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# apply scaler to training and test data\n",
    "scaled_X_train = X_scaler.transform(X_train)\n",
    "scaled_X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show details of data set\n",
    "vector_length = len(X_train[0])\n",
    "data_dict = explore_dataset(cars_train, non_cars_train, extract_time, vector_length, X_train, X_test)\n",
    "for key in sorted(data_dict):\n",
    "    print('{}:\\t'.format(key), data_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifier \n",
    "clf = svm.LinearSVC()\n",
    "\n",
    "# train classifier\n",
    "t = time.time()\n",
    "clf.fit(scaled_X_train, y_train)\n",
    "fit_time = round(time.time() - t, 2)\n",
    "print(fit_time, 'seconds to train classifier')\n",
    "\n",
    "\n",
    "# check accuracy on test set\n",
    "accuracy = clf.score(scaled_X_test, y_test)\n",
    "print('Accuracy of SVM on test set: {:.5f} on test set of {} images'.format(accuracy, len(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to pickle file\n",
    "svm_pickle = {'svm':clf, 'classifier accuracy':accuracy 'scaler':X_scaler, 'data_dict':data_dict}\n",
    "outfile = open('svm_pickle.p', 'wb')\n",
    "pickle.dump(svm_pickle, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open pickle file with training features\n",
    "infile = open('svm_pickle.p', 'rb')\n",
    "class_pickle = pickle.load(infile)\n",
    "infile.close()\n",
    "clf = class_pickle['svm']\n",
    "X_scaler = class_pickle['scaler']\n",
    "data_dict = class_pickle['data_dict']\n",
    "acc = class_pickle['classifier accuracy']\n",
    "\n",
    "print('classifier accuracy: ', acc)\n",
    "\n",
    "for key in sorted(data_dict):\n",
    "    print('{}:\\t'.format(key), data_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to save and threshold heat maps over nframes\n",
    "class Maps(object):\n",
    "    def __init__(self, nframes):\n",
    "        self.heatmaps = deque(maxlen=nframes)\n",
    "        self.total_heat = None\n",
    "#         self.archive = []\n",
    "        \n",
    "    def add_map(self, heatmap):\n",
    "        # add current heatmap to running list\n",
    "        self.heatmaps.append(heatmap)\n",
    "        self.total_heat = sum(self.heatmaps)\n",
    "#         self.archive.append(self.total_heat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_vehicles(image):\n",
    "    # code assumes cv2.imread() == BGR so convert to BGR for now\n",
    "    # toggle video = on, test_images = off\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    t = time.time()\n",
    "    # use subsample() to search image and detect vehicles\n",
    "    car_windows, window_count = subsample(image, ybounds_list, xbounds_list, scale_list, clf, X_scaler, orient, pix_per_cell, cell_per_block,\\\n",
    "                            cspace, nbins, spatial_size, hog_channel=hog_channel, hog_feat=hog_feat,\\\n",
    "                            hist_feat=hist_feat, spatial_feat=spatial_feat)\n",
    "    \n",
    "    # create empty heatmap\n",
    "    heatmap = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    # add heat for single frame\n",
    "    heatmap = add_heat(heatmap, car_windows)\n",
    "    # add current frame's heatmap to running heatmap list\n",
    "    maps.add_map(heatmap)\n",
    "    # threshold running heat map\n",
    "    heatmap = maps.total_heat\n",
    "    heatmap = heat_thresh(heatmap, 7)\n",
    "    # create labels from heat map\n",
    "    heat_labels = label(heatmap)\n",
    "    # find boxes from labels\n",
    "    hot_boxes = find_heat_boxes(image, heat_labels)\n",
    "    \n",
    "    # draw boxes onto image\n",
    "    draw_img = np.copy(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw_img = draw_boxes(draw_img, hot_boxes)\n",
    "#     draw_img = draw_boxes(draw_img, car_windows)\n",
    "    \n",
    "    print('run time: ', time.time()-t, ' seconds')\n",
    "    print('searching: {} windows'.format(window_count))\n",
    "    print('')\n",
    "    return draw_img, heatmap, hot_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create maps instance\n",
    "# # set nframes on initialization\n",
    "nframes = 10\n",
    "maps = Maps(nframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIDEO OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vid frames == RGB (0,255)\n",
    "# create video\n",
    "vid_output = 'output_images/output_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\") #.subclip(0,10)\n",
    "white_clip = clip1.fl_image(detect_vehicles) \n",
    "%time white_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output video\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(vid_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "### HISTOGRAM VISUALIZATION ###\n",
    "#####################\n",
    "\n",
    "# # load images\n",
    "# cutout_images = glob.glob('cutout_images/cars/*')\n",
    "# img = cv2.imread(cutout_images[0])\n",
    "# img = cv2.resize(img, (2560,2560))\n",
    "# img = convert_color(img, convert='HSV')\n",
    "\n",
    "# features = color_hist(img)\n",
    "# plt.imshow(img)\n",
    "\n",
    "# print(len(features))\n",
    "\n",
    "# # channel1, channel2, channel3, bin_centers, feature_vector = color_hist(temp_img)\n",
    "\n",
    "# # ## plot individual histograms ##\n",
    "# # fig = plt.figure(figsize=(12,3))\n",
    "# # plt.subplot(131)\n",
    "# # plt.bar(bin_centers, channel1[0])\n",
    "# # plt.xlim(0, 256)\n",
    "# # plt.title('Channel 1 Histogram')\n",
    "# # plt.subplot(132)\n",
    "# # plt.bar(bin_centers, channel2[0])\n",
    "# # plt.xlim(0, 256)\n",
    "# # plt.title('Channel 2 Histogram')\n",
    "# # plt.subplot(133)\n",
    "# # plt.bar(bin_centers, channel3[0])\n",
    "# # plt.xlim(0, 256)\n",
    "# # plt.title('Channel 3 Histogram')\n",
    "# # fig.tight_layout()\n",
    "\n",
    "\n",
    "#####################\n",
    "### SPATIAL BIN VISUALIZATION ###\n",
    "#####################\n",
    "\n",
    "# ## remove .ravel() in function\n",
    "\n",
    "# cutout_images = glob.glob('cutout_images/cars/*')\n",
    "# img = cv2.imread(cutout_images[0])\n",
    "\n",
    "# features = bin_spatial(img, size=(64,64))\n",
    "# print(len(features))\n",
    "\n",
    "# # show image\n",
    "# # plt.imshow(img)\n",
    "# # plt.imshow(bin_spatial(img, size=(64,64)))\n",
    "\n",
    "\n",
    "#####################\n",
    "### HOG VISUALIZATION ###\n",
    "#####################\n",
    "    \n",
    "# # load images\n",
    "# template_images = glob.glob('cutout_images/cars/*')\n",
    "# img = cv2.imread(template_images[3])\n",
    "\n",
    "# # parameters for hog function\n",
    "# orient = 10\n",
    "# pix_cell = 6\n",
    "# cell_block = 4\n",
    "\n",
    "# # convert to gray\n",
    "# gray = cv2.cvtColor(img_r, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# # get hog_features and hog_image\n",
    "# hog_feat, hog_img = get_hog_features(gray, orient, pix_cell, cell_block, vis=True)\n",
    "\n",
    "# # show images\n",
    "# plt.figure()\n",
    "# plt.imshow(img)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(hog_img, cmap='gray')\n",
    "\n",
    "\n",
    "#####################\n",
    "### SLIDING WINDOW VISUALIZATION ###\n",
    "#####################\n",
    "\n",
    "# # load images\n",
    "# test_images = glob.glob('test_images/*')\n",
    "# img = cv2.imread(test_images[6])\n",
    "# rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # define windows\n",
    "# windows = slide_windows(img, x_start_stop=x_bounds, y_start_stop=y_bounds, xy_window=window, xy_overlap=overlap)\n",
    "# boxed_image = draw_boxes(rgb, windows)\n",
    "\n",
    "# # show images\n",
    "# plt.figure()\n",
    "# plt.imshow(rgb)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(boxed_image)\n",
    "\n",
    "#####################\n",
    "### HOT WINDOWS VISUALIZATION ###\n",
    "#####################\n",
    "\n",
    "\n",
    "# car_boxes = search_windows(img, windows, clf, X_scaler, orient, pix_per_cell, cell_per_block, color_space=cspace,\\\n",
    "#                            nbins=nbins, size=spatial_size, hog_channel=hog_channel,\\\n",
    "#                            hist_feat=hist_feat, spatial_feat=spatial_feat, hog_feat=hog_feat)\n",
    "# detected_image = draw_boxes(rgb, car_boxes)\n",
    "# plt.imshow(detected_image)\n",
    "\n",
    "#####################\n",
    "### HEAT MAP VISUALIZATION ###\n",
    "#####################\n",
    "\n",
    "\n",
    "# box_list = car_boxes # use car boxes from previous cell\n",
    "# image = detected_image # use detected image from previous cell\n",
    "# heatmap = np.zeros_like(image[:,:,0]).astype(np.float) # define heatmap\n",
    "\n",
    "# # create heatmap\n",
    "# heat = add_heat(heatmap, box_list)\n",
    "# heat = heat_thresh(heat, 1)\n",
    "# # create labels from heatmap\n",
    "# labels = label(heatmap)\n",
    "# print(labels[1], 'cars found')\n",
    "\n",
    "# # find and draw box boundaries based on heat map\n",
    "# heat_boxes = find_heat_boxes(image, labels)\n",
    "# heatbox_image = draw_boxes(img, heat_boxes)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(image)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(heat, cmap='hot')\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(heatbox_image)\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "### SUB SAMPLING VISUALIZATION ###\n",
    "#####################\n",
    "# test = glob.glob('test_images/*')\n",
    "# img = cv2.imread(test[0])\n",
    "\n",
    "# car_windows = subsample(img, [400,600], 1.5, clf, X_scaler, 9, 8, 2, color_space='YCrCb')\n",
    "# detected_image = draw_boxes(img, car_windows)\n",
    "# plt.imshow(detected_image)\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "### TESTING PIPELINE VISUALIZATION ###\n",
    "#####################\n",
    "\n",
    "# load test_images --- jpeg and png, BGR (0,255)\n",
    "# test_images = glob.glob('test_images/*')\n",
    "# for i in range(len(test_images)):\n",
    "#     img = cv2.imread(test_images[i])\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     plt.figure()\n",
    "#     plt.imshow(img)\n",
    "\n",
    "\n",
    "# image_list = []\n",
    "# for image in test_images[10:11]:\n",
    "#     # convert image\n",
    "#     image_bgr = cv2.imread(image)\n",
    "#     # run test image through pipeline\n",
    "#     detected_image, heatmap, hot_boxes = detect_vehicles(image_bgr)\n",
    "#     # append processed image to list\n",
    "#     image_list.append(detected_image)\n",
    "    \n",
    "    \n",
    "# # show images\n",
    "# for img in image_list:\n",
    "#     plt.figure()\n",
    "#     plt.imshow(img)\n",
    "    \n",
    "# plt.figure()\n",
    "# plt.imshow(heatmap, cmap='hot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
