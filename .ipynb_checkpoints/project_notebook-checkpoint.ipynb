{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for vehicle detection in video\n",
    "1. Choose colorspace to use for feature extraction\n",
    "2. Convert image to selected colorspace\n",
    "2. Extract desired features (bin_spatial, color_hist, hog_features, etc) from converted image\n",
    "3. Combine all extracted feature vectors and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw boxes after corners are detected\n",
    "# boxes argument is an array of tuples, one for each box to draw, 2 corners in each box\n",
    "# boxes = [((corner1), (corner2)), ((corner1), (corner2)), ((corner1), (corner2))]\n",
    "# corners = (x,y)\n",
    "def draw_boxes(img, boxes, color=(0,0,255), thick=6):\n",
    "    # make copy of image\n",
    "    draw_image = np.copy(img)\n",
    "    # draw each box in boxes list\n",
    "    for box in boxes:\n",
    "        cv2.rectangle(draw_image, box[0], box[1], color, thick)\n",
    "    \n",
    "    return draw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## VISUALIZATION ##\n",
    "# ###################\n",
    "# # load images\n",
    "# test_images = glob.glob('test_images/*')\n",
    "# image_num = 3\n",
    "# img = mpimg.imread(test_images[image_num])\n",
    "# plt.imshow(img)\n",
    "\n",
    "# boxes = [((800,400),(950, 510)), ((1020,400),(1275,510))]\n",
    "# plt.imshow(draw_boxes(img, boxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataset(car_images, noncar_images):\n",
    "    data_dict = {}\n",
    "    data_dict['num_cars'] = len(car_images)\n",
    "    data_dict['num_noncars'] = len(noncar_images)\n",
    "    example_image = cv2.imread(car_image[0])\n",
    "    data_dict['image_shape'] = example_image.shape\n",
    "    data_dict['data_type'] = example_image.dtype\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Highly dependent on finding exact matches\n",
    "+ Differences that occur frame to frame such as lighting, size, and orientation cause it to fail miserably\n",
    "+ Doesn't work for vehicle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template_images = glob.glob('template_images/*')\n",
    "# img = mpimg.imread(template_images[0])\n",
    "# templates = template_images[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # search for template in image\n",
    "# def match_template(img, templates):\n",
    "#     # define empty boxes list\n",
    "#     bboxes_list = []\n",
    "    \n",
    "#     for template_path in templates:\n",
    "#         # read in template image\n",
    "#         template_img = mpimg.imread(template_path)\n",
    "#         # find best match using squared difference\n",
    "#         result = cv2.matchTemplate(img, template_img, method=cv2.TM_SQDIFF)\n",
    "#         # locate min and max locations\n",
    "#         min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "#         # set bounding box sizes based on template shape\n",
    "#         w,h = template_img.shape[1], template_img.shape[0]\n",
    "#         # define coordinates using min or max location\n",
    "#         top_left = min_loc\n",
    "#         bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "#         # append coordinates of boxes to bboxes_list\n",
    "#         bboxes_list.append((top_left, bottom_right))\n",
    "        \n",
    "#     return bboxes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes = match_template(img, templates)\n",
    "# drawn_img = draw_boxes(img, boxes)\n",
    "# plt.imshow(drawn_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore color spaces to use as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # load images\n",
    "# colorspace_cutouts = glob.glob('colorspace_cutouts/*')\n",
    "# test_images = colorspace_cutouts[6:]\n",
    "# cars = colorspace_cutouts[:3]\n",
    "# background = colorspace_cutouts[3:]\n",
    "# cutout = cv2.imread(background[0])\n",
    "# test_img = cv2.imread(test_images[2])\n",
    "\n",
    "\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# %matplotlib notebook\n",
    "\n",
    "# def plot3d(pixels, colors_rgb,\n",
    "#         axis_labels=list(\"RGB\"), axis_limits=((0, 255), (0, 255), (0, 255))):\n",
    "#     \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "#     # Create figure and 3D axes\n",
    "#     fig = plt.figure(figsize=(8, 8))\n",
    "#     ax = Axes3D(fig)\n",
    "\n",
    "#     # Set axis limits\n",
    "#     ax.set_xlim(*axis_limits[0])\n",
    "#     ax.set_ylim(*axis_limits[1])\n",
    "#     ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "#     # Set axis labels and sizes\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "#     ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "#     ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "#     ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "#     # Plot pixel values with colors given in colors_rgb\n",
    "#     ax.scatter(\n",
    "#         pixels[:, :, 0].ravel(),\n",
    "#         pixels[:, :, 1].ravel(),\n",
    "#         pixels[:, :, 2].ravel(),\n",
    "#         c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "#     return ax  # return Axes3D object for further manipulation\n",
    "\n",
    "\n",
    "# # Read a color image\n",
    "# img = cutout\n",
    "\n",
    "# # Select a small fraction of pixels to plot by subsampling it\n",
    "# scale = max(img.shape[0], img.shape[1], 64) / 64  # at most 64 rows and columns\n",
    "# img_small = cv2.resize(img, (np.int(img.shape[1] / scale), np.int(img.shape[0] / scale)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# # Convert subsampled image to desired color space(s)\n",
    "# img_small_RGB = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, matplotlib likes RGB\n",
    "# img_small_HSV = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)\n",
    "# img_small_HLS = cv2.cvtColor(img_small, cv2.COLOR_BGR2HLS)\n",
    "# img_small_LUV = cv2.cvtColor(img_small, cv2.COLOR_BGR2LUV)\n",
    "# img_small_rgb = img_small_RGB / 255.  # scaled to [0, 1], only for plotting\n",
    "\n",
    "# # show original image\n",
    "# plt.imshow(img)\n",
    "\n",
    "# # Plot and show\n",
    "# plot3d(img_small_RGB, img_small_rgb)\n",
    "# plt.show()\n",
    "\n",
    "# plot3d(img_small_HSV, img_small_rgb, axis_labels=list(\"HSV\"))\n",
    "# plt.show()\n",
    "\n",
    "# plot3d(img_small_HLS, img_small_rgb, axis_labels=list(\"HLS\"))\n",
    "# plt.show()\n",
    "\n",
    "# plot3d(img_small_LUV, img_small_rgb, axis_labels=list(\"LUV\"))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find histograms of each color channel\n",
    "def color_hist(img, nbins=32, bins_range=(0,256)):\n",
    "    # find histograms of each color channel\n",
    "    channel1 = np.histogram(img[:,:,0], nbins, bins_range)\n",
    "    channel2 = np.histogram(img[:,:,1], nbins, bins_range)\n",
    "    channel3 = np.histogram(img[:,:,2], nbins, bins_range)\n",
    "    \n",
    "    # concatenate into single feature vector\n",
    "    hist_features = np.concatenate((channel1[0], channel2[0], channel3[0]))\n",
    "    \n",
    "    ## VISUALIZATION ##\n",
    "    # calculate bin centers based on nbins and bins_range parameters\n",
    "#     bin_edges = channel1[1]\n",
    "#     bin_centers = (bin_edges[1:] + bin_edges[:len(bin_edges)-1]) / 2\n",
    "#     return channel1, channel2, channel3, bin_centers, feature_vector\n",
    "\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## VISUALIZATION ##\n",
    "# ###################\n",
    "\n",
    "# # load images\n",
    "# template_images = glob.glob('template_images/*')\n",
    "# img = mpimg.imread(template_images[0])\n",
    "# templates = template_images[1:]\n",
    "# temp_img = mpimg.imread(templates[0])\n",
    "\n",
    "\n",
    "# channel1, channel2, channel3, bin_centers, feature_vector = color_hist(temp_img)\n",
    "\n",
    "\n",
    "# ## plot individual histograms ##\n",
    "# fig = plt.figure(figsize=(12,3))\n",
    "# plt.subplot(131)\n",
    "# plt.bar(bin_centers, rhist[0])\n",
    "# plt.xlim(0, 256)\n",
    "# plt.title('R Histogram')\n",
    "# plt.subplot(132)\n",
    "# plt.bar(bin_centers, ghist[0])\n",
    "# plt.xlim(0, 256)\n",
    "# plt.title('G Histogram')\n",
    "# plt.subplot(133)\n",
    "# plt.bar(bin_centers, bhist[0])\n",
    "# plt.xlim(0, 256)\n",
    "# plt.title('B Histogram')\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial binned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after selecting colorspace which best separates car pixels, use it to define a feature vector\n",
    "def bin_spatial(img, size=(32,32)):\n",
    "        \n",
    "    bin_spatial_features = cv2.resize(img, size).ravel()\n",
    "    \n",
    "    return bin_spatial_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VISUALIZATION ##\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOG gradient features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gradient vector to add structural information to the classifier\n",
    "# accepts single color channel or grayscale\n",
    "def hog_features(img, orient, pix_per_cell, cell_per_block, vis=True, feature_vec=True):\n",
    "    return_values = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell), \\\n",
    "                       cells_per_block=(cell_per_block,cell_per_block), visualise=True, feature_vector=feature_vec, \\\n",
    "                       block_norm=\"L2-Hys\")\n",
    "    \n",
    "    hog_features = return_values[0]\n",
    "    if vis:\n",
    "        hog_image = return_values[1]\n",
    "        return hog_features, hog_image\n",
    "    else:\n",
    "        return hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VISUALIZATION ##\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to extract all feature vectors from image to combine and scale\n",
    "# Parameters must match parameters of all extraction functions called\n",
    "# inputs list of image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img_list, orient, pix_per_cell, cell_per_block, color_space='RGB',\\\n",
    "                     nbins=32, bins_range=(0,256), size=(32,32), vis=False, feature_vec=True):\n",
    "    \n",
    "    # create features list, append vector for each image\n",
    "    features_list = []\n",
    "    for image in img_list:\n",
    "        # read in image using cv2 = BGR\n",
    "        img = cv2.imread(image)\n",
    "        # convert to selected colorspace\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        else: \n",
    "            feature_image =  cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # create color histogram features\n",
    "        hist_vector = color_hist(feature_image, nbins, bins_range)\n",
    "#         print(hist_vector.shape)\n",
    "        # create spatial binned features\n",
    "        spatial_bin_vector = bin_spatial(feature_image, size)\n",
    "#         print(spatial_bin_vector.shape)\n",
    "        # create hog features\n",
    "        gray = cv2.cvtColor(feature_image, cv2.COLOR_RGB2GRAY)\n",
    "        hog_vector = hog_features(gray, orient, pix_per_cell, cell_per_block, vis, feature_vec)\n",
    "#         print(hog_vector.shape)\n",
    "        \n",
    "        # concatenate features for each image\n",
    "        image_features = np.concatenate((hist_vector, spatial_bin_vector, hog_vector))\n",
    "        # append to list for each image\n",
    "        features_list.append(image_features)\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST EXTRACTION FUNCTION ##\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "cspace = 'HSV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = glob.glob('vehicle_training_set/vehicles_smallset/*.jpeg')\n",
    "non_cars = glob.glob('vehicle_training_set/non-vehicles_smallset/*.jpeg')\n",
    "cars_train = cars[:10]\n",
    "non_cars_train = non_cars[:10]\n",
    "\n",
    "cars_features = extract_features(cars_train, orient, pix_per_cell, cell_per_block, color_space=cspace)\n",
    "non_cars_features = extract_features(non_cars_train, orient, pix_per_cell, cell_per_block, color_space=cspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all training feature vectors into 2D array\n",
    "feature_list = [cars_features, non_cars_features]\n",
    "# create 2D list of type float64 to scale\n",
    "X = np.vstack(feature_list).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIT ON TRAINING DATA ONLY\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "\n",
    "## USE ABOVE FIT TO TRANSFORM TRAINING AND TEST DATA ##\n",
    "\n",
    "# apply scaler to data\n",
    "scaled_X = X_scaler.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
